{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open in colab: https://colab.research.google.com/github/bonacor/pytorch1/blob/master/pytorch_in_7_days___2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2444,
     "status": "ok",
     "timestamp": 1564993932725,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -120
    },
    "id": "pY4zk00_54xt",
    "outputId": "51d32b35-4b1f-4c44-bbd1-05dd45971f1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WNpcEAP54xy"
   },
   "source": [
    "## Advanced tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phsBxqIh54xz"
   },
   "outputs": [],
   "source": [
    "# You'll need a GPU to get this to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhK_pvWo54x1"
   },
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1564994497657,
     "user": {
      "displayName": "Daniele Bonacorsi",
      "photoUrl": "https://lh3.googleusercontent.com/-K-avyI63T6M/AAAAAAAAAAI/AAAAAAAAEMA/CMUZOZUvzXw/s64/photo.jpg",
      "userId": "01397661520201218305"
     },
     "user_tz": -120
    },
    "id": "DvnPWmxR54x3",
    "outputId": "3bae9521-cc4b-4968-ea6c-d400167ad47b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu = torch.device('cpu')\n",
    "gpu = torch.device('cuda')\n",
    "cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1564994498799,
     "user": {
      "displayName": "Daniele Bonacorsi",
      "photoUrl": "https://lh3.googleusercontent.com/-K-avyI63T6M/AAAAAAAAAAI/AAAAAAAAEMA/CMUZOZUvzXw/s64/photo.jpg",
      "userId": "01397661520201218305"
     },
     "user_tz": -120
    },
    "id": "oTcSIy3w54x5",
    "outputId": "f754c39e-63b7-4621-df23-03e892ab4c15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1564994499223,
     "user": {
      "displayName": "Daniele Bonacorsi",
      "photoUrl": "https://lh3.googleusercontent.com/-K-avyI63T6M/AAAAAAAAAAI/AAAAAAAAEMA/CMUZOZUvzXw/s64/photo.jpg",
      "userId": "01397661520201218305"
     },
     "user_tz": -120
    },
    "id": "5kS7rxuK54x7",
    "outputId": "bec46dcf-e28f-4445-8ca7-28e169c29895"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "703-k2PE54x9"
   },
   "outputs": [],
   "source": [
    "# when you allocate a tensor, it's on a device, in the context\n",
    "# of that device, if you don't specify, it's on the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1564994501312,
     "user": {
      "displayName": "Daniele Bonacorsi",
      "photoUrl": "https://lh3.googleusercontent.com/-K-avyI63T6M/AAAAAAAAAAI/AAAAAAAAEMA/CMUZOZUvzXw/s64/photo.jpg",
      "userId": "01397661520201218305"
     },
     "user_tz": -120
    },
    "id": "UBfAPmlQ54yA",
    "outputId": "f8678a4c-731a-4691-98c5-7c5a100d060c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.5000]), device(type='cpu'))"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.5])\n",
    "x, x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lphVX5-d54yC"
   },
   "outputs": [],
   "source": [
    "# you can explicitly place it, which is how one does it in general. result is in this case just the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1564994503512,
     "user": {
      "displayName": "Daniele Bonacorsi",
      "photoUrl": "https://lh3.googleusercontent.com/-K-avyI63T6M/AAAAAAAAAAI/AAAAAAAAEMA/CMUZOZUvzXw/s64/photo.jpg",
      "userId": "01397661520201218305"
     },
     "user_tz": -120
    },
    "id": "wBKCBU1Z54yE",
    "outputId": "935781b9-8697-4ce0-dd7f-daa251b20b5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.5000]), device(type='cpu'))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([2.5], device=cpu)\n",
    "y, y.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_Z3urY-54yH"
   },
   "outputs": [],
   "source": [
    "# and now -- GPU\n",
    "#\n",
    "# NOTE: if you do not have access to a a GPU, the cell(s) below will give error\n",
    "# (e.g. \"AssertionError: Torch not compiled with CUDA enabled\")\n",
    "# if you have GPU, you should see e.g.:\n",
    "# (tensor([3.5000], device='cuda:0'), device(type='cuda', index=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1564994608253,
     "user": {
      "displayName": "Daniele Bonacorsi",
      "photoUrl": "https://lh3.googleusercontent.com/-K-avyI63T6M/AAAAAAAAAAI/AAAAAAAAEMA/CMUZOZUvzXw/s64/photo.jpg",
      "userId": "01397661520201218305"
     },
     "user_tz": -120
    },
    "id": "wOj3suRB54yK",
    "outputId": "e8985d3f-9617-466d-a680-4baa01fdb8ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000], device='cuda:0'), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.tensor([3.5], device=gpu)\n",
    "z, z.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEeASVRr8fPR"
   },
   "outputs": [],
   "source": [
    "# you cannot mix devices, this is the important thing to remember\n",
    "# particularly when loading up data -- make sure you put things\n",
    "# together on a device!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1277,
     "status": "error",
     "timestamp": 1564994989804,
     "user": {
      "displayName": "Daniele Bonacorsi",
      "photoUrl": "https://lh3.googleusercontent.com/-K-avyI63T6M/AAAAAAAAAAI/AAAAAAAAEMA/CMUZOZUvzXw/s64/photo.jpg",
      "userId": "01397661520201218305"
     },
     "user_tz": -120
    },
    "id": "0PdwNEYY800C",
    "outputId": "c9b076b5-f4bf-445c-9baf-874f6dd09458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1.5000]) on device: cpu\n",
      "y: tensor([2.5000]) on device: cpu\n",
      "z: tensor([3.5000], device='cuda:0') on device: cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-728b69836cb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"z:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on device:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# this should give error:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected backend CPU and dtype Float but got backend CUDA and dtype Float"
     ]
    }
   ],
   "source": [
    "print(\"x:\", x, \"on device:\", x.device)\n",
    "print(\"y:\", y, \"on device:\", y.device)\n",
    "print(\"z:\", z, \"on device:\", z.device)\n",
    "# this should give error:\n",
    "a = x + y + z\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pp63kMbJ803K"
   },
   "outputs": [],
   "source": [
    "# but you can move things around to work on the gpu\n",
    "# andf this should not give errors any more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1564995226317,
     "user": {
      "displayName": "Daniele Bonacorsi",
      "photoUrl": "https://lh3.googleusercontent.com/-K-avyI63T6M/AAAAAAAAAAI/AAAAAAAAEMA/CMUZOZUvzXw/s64/photo.jpg",
      "userId": "01397661520201218305"
     },
     "user_tz": -120
    },
    "id": "UrgGZ89e805l",
    "outputId": "b9694711-870d-41a2-e7a1-a59dc2345568"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.5000], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = x.to(gpu) + y.to(gpu) + z\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1302,
     "status": "ok",
     "timestamp": 1564995127749,
     "user": {
      "displayName": "Daniele Bonacorsi",
      "photoUrl": "https://lh3.googleusercontent.com/-K-avyI63T6M/AAAAAAAAAAI/AAAAAAAAEMA/CMUZOZUvzXw/s64/photo.jpg",
      "userId": "01397661520201218305"
     },
     "user_tz": -120
    },
    "id": "6VzkBKi4808P",
    "outputId": "d2e497bd-f6c6-4aad-b979-db7ce5a1a45f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7.5000]), device(type='cpu'))"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more cleanly (and showing that one can move things back to the CPU, too):\n",
    "a, a.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1080,
     "status": "ok",
     "timestamp": 1564995134796,
     "user": {
      "displayName": "Daniele Bonacorsi",
      "photoUrl": "https://lh3.googleusercontent.com/-K-avyI63T6M/AAAAAAAAAAI/AAAAAAAAEMA/CMUZOZUvzXw/s64/photo.jpg",
      "userId": "01397661520201218305"
     },
     "user_tz": -120
    },
    "id": "KhKNWxPI80-w",
    "outputId": "07403fe3-069d-4791-edbb-4c325472a152"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7.5000]), device(type='cpu'))"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.to(cpu)\n",
    "b, b.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1564995502820,
     "user": {
      "displayName": "Daniele Bonacorsi",
      "photoUrl": "https://lh3.googleusercontent.com/-K-avyI63T6M/AAAAAAAAAAI/AAAAAAAAEMA/CMUZOZUvzXw/s64/photo.jpg",
      "userId": "01397661520201218305"
     },
     "user_tz": -120
    },
    "id": "oxZ9BfB_81Ba",
    "outputId": "3dee408f-9ee2-4440-eb49-6b93da061204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1.5000]) on device: cpu\n",
      "y: tensor([2.5000]) on device: cpu\n",
      "z: tensor([3.5000], device='cuda:0') on device: cuda:0\n",
      "\n",
      "Assign new vars and use GPU:\n",
      "\n",
      "x_gpu: tensor([1.5000]) on device: cuda:0\n",
      "y_gpu: tensor([2.5000]) on device: cuda:0\n",
      "\n",
      "Run operation here\n",
      "\n",
      "a: tensor([7.5000], device='cuda:0') on device: cuda:0\n",
      "\n",
      "Bring the result (a) back to CPU\n",
      "\n",
      "a_cpu: tensor([2.5000]) on device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"x:\", x, \"on device:\", x.device)\n",
    "print(\"y:\", y, \"on device:\", y.device)\n",
    "print(\"z:\", z, \"on device:\", z.device)\n",
    "#\n",
    "print(\"\\nAssign new vars and use GPU:\\n\")\n",
    "x_gpu = x.to(gpu)\n",
    "y_gpu = y.to(gpu)\n",
    "print(\"x_gpu:\", x, \"on device:\", x_gpu.device)\n",
    "print(\"y_gpu:\", y, \"on device:\", y_gpu.device)\n",
    "#\n",
    "print(\"\\nRun operation here\\n\")\n",
    "#\n",
    "#a = x.to(gpu) + y.to(gpu) + z\n",
    "a = x_gpu + y_gpu + z\n",
    "#\n",
    "print(\"a:\", a, \"on device:\", a.device)\n",
    "#\n",
    "print(\"\\nBring the result (a) back to CPU\\n\")\n",
    "a_cpu = a.to(cpu)\n",
    "print(\"a_cpu:\", y, \"on device:\", a_cpu.device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch_in_7_days___2-colab.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/bonacor/pytorch1/blob/master/pytorch_in_7_days___2.ipynb",
     "timestamp": 1564994111261
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
